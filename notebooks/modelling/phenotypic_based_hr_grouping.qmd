---
title: "HR predicion: phenotype"
author: "AG"
format: html
editor: source
---

## Intro

HR grouping 1+2 (HR) & 3+4 (nonHR) is a grouping based on clinical breakpoint

HR grouping 1+3 & 2+4 is a grouping based on phenotype.

Here I will explore this phenotypic classification scheme.

## Data

```{r, message=FALSE}
library(tidyverse)
library(tidymodels)
library(themis)
library(embed)
library(bonsai)
source("functions.R")
fit_save_path <- "~/Data/HeteroR/results/models/scheme13/"
```


```{r}
data_strain <- read_csv("data/features_strain.csv", na = c("NA", "-Inf"), show_col_types = F) %>% 
  filter(strain != "DA63310") %>%  
  select(-contains("oriC")) %>% 
  select(-contains("plus")) %>% 
  mutate(n.beta.lac.4 = factor(ifelse(n.beta.lac > 4, "yes", "no"))) %>% 
  relocate(n.beta.lac.4, .before = "n.plasmids") %>% 
  mutate(chrom.status = factor(chrom.status))

data_strain$N50 <- NULL
data_strain[is.na(data_strain)] <- 0
```

Here I will assign HR/nonHR classes based on phenotype, not on clinical breakpoint.

```{r}
res_groups <- read_csv("data/resistance_testing_groups.csv", show_col_types = F) %>% 
  mutate(group = if_else(is.na(group), "NA", group)) %>% 
  filter(group != "R",
         group != "CONT.",
         !grepl("Exclude", group))
  
res_groups %>% group_by(group) %>% count()
```
So, 8 fold (HR) = I + III,
    4 fold (nonHR?) = II + IV,
    the rest (?) = NA + V + "III or V"
    
```{r}
res_groups <- res_groups %>% 
  mutate(resistance = case_when(
    group == "I" | group == "III" ~ "8_fold",
    group == "II" | group == "IV" ~ "4_fold",
    .default = "other"
  )) %>% 
  select(-group)

res_groups %>% group_by(resistance) %>% count()
```

```{r}
data_strain <- left_join(res_groups, data_strain, by = "strain")
```

## EDA

```{r}
umap_yj_recipe <- 
  recipe(resistance ~ ., data = data_strain) %>%
  update_role(strain, new_role = "ID") %>%
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>%
  step_YeoJohnson(all_numeric_predictors())  %>%
  step_normalize(all_numeric_predictors()) %>% 
    step_umap(
    all_numeric_predictors(),
    num_comp = 10,
    min_dist = 0.8,
    neighbors = 25
  ) %>% 
  step_normalize(all_numeric_predictors())

umap_yj_recipe %>%
  prep() %>% 
  juice() %>% 
  plot_validation_results(c("UMAP01", "UMAP02", "UMAP03", "UMAP04")) +
  ggtitle("UMAP unsupervised")
```

```{r}
umap_sup_yj_recipe <- 
  recipe(resistance ~ ., data = data_strain) %>%
  update_role(strain, new_role = "ID") %>%
  step_nzv(all_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_YeoJohnson(all_numeric_predictors())  %>%
  step_normalize(all_numeric_predictors()) %>% 
    step_umap(
    all_numeric_predictors(),
    outcome = "resistance",
    num_comp = 10,
    min_dist = 0.8,
    neighbors = 25
  ) %>% 
  step_normalize(all_numeric_predictors())

umap_sup_yj_recipe %>%
  prep() %>% 
  juice() %>% 
  plot_validation_results(c("UMAP01", "UMAP02", "UMAP03", "UMAP04")) +
  ggtitle("UMAP supervised")
```
## Split

```{r}
set.seed(124)

data_split <- initial_split(data_strain, prop = 0.8, strata = resistance)

df_train <- training(data_split)
df_test <- testing(data_split)

cv_folds <- vfold_cv(df_train, strata = "resistance", v = 10, repeats = 5) 
cls_metrics <- metric_set(roc_auc, j_index)

df_train %>% 
  count(resistance) %>% 
  mutate(prop = n/sum(n))
```

## LR model

```{r}
lr_spec <- multinom_reg(penalty = tune(),
                        mixture = 1) %>% 
  set_engine("glmnet")

base_lr_recipe <- recipe(resistance ~ ., data = df_train) %>%
  update_role(strain, new_role = "ID") %>%
  step_nzv(all_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_smote(resistance, over_ratio = 1, seed = 100)

lr_wf <- workflow(preprocessor = base_lr_recipe,
                  spec = lr_spec)

lr_res <- lr_wf %>%
  tune_grid(
    resamples = cv_folds,
    grid = 30,
    metrics = cls_metrics,
    control = control_grid(save_pred = TRUE,
                           save_workflow = TRUE)
  )

lr_best_fit <- fit_best(lr_res)
saveRDS(lr_best_fit, paste0(fit_save_path, "lr_base_best_fit.rds"))

show_best(lr_res, metric = "roc_auc")
```

```{r}
lr_res %>%
  collect_predictions() %>%
  roc_curve(resistance, .pred_8_fold, .pred_4_fold, .pred_other) %>%
  ggplot(aes(
    x = 1 - specificity,
    y = sensitivity,
    col = .level
  )) +
  geom_path(lwd = 0.5, alpha = 0.8) +
  geom_abline(lty = 3) +
  coord_equal() +
  scale_color_brewer(palette = "Set1") +
  ggtitle("Multinomial LR, ROC curves")
```


## GBT model

```{r}
gbt_spec <- boost_tree(
      trees = tune(),
      mtry = tune(),
      min_n = tune(),
      tree_depth = tune(),
      learn_rate = tune(),
      loss_reduction = tune(),
      sample_size = tune(),
      stop_iter = tune()) %>%
      set_engine("lightgbm", num.threads = 8) %>%
      set_mode("classification") %>% translate()

base_gbt_recipe <- recipe(resistance ~ ., data = df_train) %>%
  update_role(strain, new_role = "ID") %>%
  step_nzv(all_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_smote(resistance, over_ratio = 1, seed = 100)

gbt_wf <- workflow(preprocessor = base_gbt_recipe, 
                   spec = gbt_spec)

gbt_param_set <-
  extract_parameter_set_dials(gbt_wf) %>%
  finalize(x = df_train %>% select(-resistance))

gbt_res <- gbt_wf %>%
  tune_grid(
    resamples = cv_folds,
    grid = 30,
    metrics = cls_metrics,
    control = control_grid(save_pred = TRUE,
                           save_workflow = TRUE)
  )

gbt_best_fit <- fit_best(gbt_res)
saveRDS(gbt_best_fit, paste0(fit_save_path, "gbt_base_best_fit.rds"))

show_best(gbt_res, metric = "roc_auc")
```

### ROC

```{r}
gbt_res %>%
  collect_predictions() %>%
  roc_curve(resistance, .pred_8_fold, .pred_4_fold, .pred_other) %>%
  ggplot(aes(
    x = 1 - specificity,
    y = sensitivity,
    col = .level
  )) +
  geom_path(lwd = 0.5, alpha = 0.8) +
  geom_abline(lty = 3) +
  coord_equal() +
  scale_color_brewer(palette = "Set1") +
  ggtitle("GBT, ROC curves")
```


### Bayesian

```{r}
gbt_bres <-
      tune_bayes(
        gbt_wf,
        resamples = cv_folds,
        initial = gbt_res,
        iter = 30,
        metrics = metric_set(roc_auc),
        param_info = gbt_param_set,
        control = control_bayes(
          no_improve = 10,
          save_pred = TRUE,
          verbose = FALSE,
          save_workflow = TRUE
        )
      )

gbt_bayes_best_fit <- fit_best(gbt_bres)
saveRDS(gbt_bayes_best_fit, paste0(fit_save_path, "gbt_bayes_base_best_fit.rds"))

show_best(gbt_bres, metric = "roc_auc")
```

```{r}
gbt_bres %>%
  collect_predictions() %>%
  roc_curve(resistance, .pred_8_fold, .pred_4_fold, .pred_other) %>%
  ggplot(aes(
    x = 1 - specificity,
    y = sensitivity,
    col = .level
  )) +
  geom_path(lwd = 0.5, alpha = 0.8) +
  geom_abline(lty = 3) +
  coord_equal() +
  scale_color_brewer(palette = "Set1") +
  ggtitle("GBT, ROC curves")
```

