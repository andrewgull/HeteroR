from snakemake.io import touch, directory, temp, expand

configfile: "config.yaml"
# command to run the pipeline on 14 threads and 10Gb of RAM:
# snakemake --use-conda --cores 14 --resources mem_mb=10000
# snakemake --dag results/final/DA63360_all.done | dot -Tpng > dag_new.png

rule all:
    input:
        expand("results/final/{strain}_all.done", strain=config['strains'])

rule QC_illumina_raw:
    input:
        "resources/data_raw/{strain}/Illumina/renamed/{strain}_1.fq.gz"
    output:
        "results/qualcheck_reads/{strain}/Illumina/{strain}_summary.tsv"
    log: "results/logs/{strain}_illumina_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_illumina_trimmed:
    input:
        "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz"
    output:
        "results/qualcheck_reads/{strain}/Illumina_trimmed/{strain}_summary.tsv"
    log: "results/logs/{strain}_trimmed_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_nanopore_raw:  # also builds length distribution plots
    input:
        "resources/data_raw/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        "results/qualcheck_reads/{strain}/Nanopore/{strain}_summary.tsv"
    log: "results/logs/{strain}_nanopore_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_nanopore_filtered:
    input:
        "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        "results/qualcheck_reads/{strain}/Nanopore_filtered/{strain}_summary.tsv"
    log: "results/logs/{strain}_filtered_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule trim_illumina:
    input:
        short_read_1 = "resources/data_raw/{strain}/Illumina/renamed/{strain}_1.fq.gz",
        short_read_2 = "resources/data_raw/{strain}/Illumina/renamed/{strain}_2.fq.gz"
    output:
        short_read_1 = "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz",
        report_html = "results/qualcheck_reads/fastp_reports/{strain}_report.html",
        report_json = "results/qualcheck_reads/fastp_reports/{strain}_report.json"
    wildcard_constraints: strain="DA[0-9]*"
    threads: 18
    message: "executing fastp with {threads} threads on {wildcards.strain} short reads"
    log: "results/logs/{strain}_fastp.log"
    conda: "envs/fastp.yaml"
    params: q="20", W="4", r="20", l="50", f="10"
    shell:
        # -q, --qualified_quality_phred
        # the quality value that a base is qualified. Default 15 means phred quality >=Q15 is qualified. (int [=15])
        # -W, --cut_window_size
        # the window size option shared by cut_front, cut_tail or cut_sliding. Range: 1~1000, default: 4 (int [=4])
        # -r, --cut_right
        # move a sliding window from front to tail, if meet one window with mean quality < threshold,
        # drop the bases in the window and the right part, and then stop.
        # -l, --length_required
        # reads shorter than length_required will be discarded, default is 15. (int [=15])
        # -y, --low_complexity_filter
        # enable low complexity filter. The complexity is defined as the percentage of base that is
        # different from its next base (base[i] != base[i+1]).
        # -f, --trim_front1
        # trimming how manythreads = snakemake.threads bases in front for read1, default is 0 (int [=0])
        "fastp --in1 {input.short_read_1} --in2 {input.short_read_2} --out1 {output.short_read_1} "
        "--out2 {output.short_read_2} "
        "--thread {threads} --qualified_quality_phred {params.q} --cut_window_size {params.W} "
        "--cut_right {params.r} --length_required {params.l} --trim_front1 {params.f} --low_complexity_filter "
        "--html {output.report_html} --json {output.report_json} &> {log}"
# coverage=$( seqkit stats -T resources/data_raw/DA62886/Nanopore/DA62886_all.fastq.gz | cut -f5 | tail -n 1 )
# expr $coverage/5131220
# exp(2.2401998 - 0.2889426*coverage)/1+add universal formula to calculate probability(exp(2.2401998 - 0.2889426*coverage))

rule smart_trim_nanopre:
    input:
        "resources/data_raw/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
         "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    message:
        "executing filtlong on {wildcards.strain} long reads using incompleteness prediction"
    log: "results/logs/{strain}_filtlong.log"
    conda: "envs/filtlong.yaml"
    threads: 18
    params: genlen=5131220, intercept=2.2401998, coeff=-0.2889426, prob_cut_off=0.70,
            min_len=5000, len_weight=1, perc=20, bases=260000000, threads=14  # old filtlong trimming params
    script:
        "scripts/trim_nanopore.py"

# rule filter_nanopore:
#     input:
#         "resources/data_raw/{strain}/Nanopore/{strain}_all.fastq.gz"
#     output:
#         "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
#     message:
#         "executing filtlong on {wildcards.strain} long reads"
#     log: "results/logs/{strain}_filtlong.log"
#     conda: "envs/filtlong.yaml"
#     threads: 14
#     params: min_len=5000, len_weight=1, perc=20, bases=260000000
#     shell:
#         "filtlong --min_length {params.min_len} --length_weight {params.len_weight} --keep_percent {params.perc} "
#         "--target_bases {params.bases} {input} 2> {log} | pigz -c -p {threads} > {output}"

rule unicycler:
    input:
        short_read_1 = "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz",
        long_read = "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        directory("results/assemblies/{strain}")
    threads: 18
    message:
        "executing Unicycler with {threads} threads on {wildcards.strain} reads"
    log:
        "results/logs/{strain}_unicycler.log"
    conda: "envs/unicycler.yaml"
    shell:
        "unicycler -1 {input.short_read_1} -2 {input.short_read_2} -l {input.long_read} -t {threads} -o {output} &> {log}"

rule QC_assembly:
    input:
        "results/assemblies/{strain}",
        "resources/busco_downloads"
    output:
        directory("results/qualcheck_assembly/{strain}")
    threads: 18
    message: "executing BUSCO and QUAST with {threads} threads on {wildcards.strain} assembly"
    conda: "envs/busco_quast.yaml"
    params: tax_dataset="gammaproteobacteria_odb10"
    script:
        "scripts/QC_assembly.py"

rule bwa_map:
    input:
        assembly_dir = "results/assemblies/{strain}",
        short_read_1= "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz"
    output:
        # an output file marked as temp is deleted after all rules that use it as an input are completed
        temp("results/mapping/{strain}/assembly.sam")
    threads: 18
    message: "executing BWA with {threads} threads on {wildcards.strain} assembly"
    log: mem = "results/logs/{strain}_bwa_mem.log",
         index = "results/logs/{strain}_bwa_index.log"
    conda: "envs/bwa.yaml"
    shell:
        "bwa index {input.assembly_dir}/assembly.fasta &> {log.index} && "
        "bwa mem -t {threads} {input.assembly_dir}/assembly.fasta {input.short_read_1} {input.short_read_2} -o {output} &> {log.mem}"

rule samtools:
    input:
        "results/mapping/{strain}/assembly.sam"
    output:
        "results/mapping/{strain}/assembly.bam"
    threads: 18
    message: "executing SAMTOOLS: VIEW-SORT with {threads} threads on {wildcards.strain} mapping file"
    log: "results/logs/{strain}_samtools.log"
    conda: "envs/samtools.yaml"
    shell:
        "samtools view -b {input} | samtools sort -o {output} -O BAM -@ {threads} &> {log} && samtools index {output}"

rule unmapped:
    input:
        "results/mapping/{strain}/assembly.bam"
    output:
        r1 = "results/mapping/{strain}/unmapped_1.fastq",
        r2 = "results/mapping/{strain}/unmapped_2.fastq"
    threads: 18
    message: "executing SAMTOOLS: VIEW-FASTQ with {threads} threads on {wildcards.strain} BAM file"
    log: "results/logs/{strain}_unmapped.log"
    conda: "envs/samtools.yaml"
    shell:
        "samtools view -@ {threads} -u -f 12 -F 256 {input} | samtools fastq -1 {output.r1} -2 {output.r2} -@ {threads} &> {log}"

rule plasmid_assembly:
    input:
        r1 = "results/mapping/{strain}/unmapped_1.fastq",
        r2 = "results/mapping/{strain}/unmapped_2.fastq"
    output:
        directory("results/plasmids/{strain}")
    threads: 18
    message: "executing SPAdes in plasmid mode with {threads} threads on unmapped reads of {wildcards.strain}"
    log: "results/logs/{strain}_spades.log"
    conda: "envs/spades.yaml"
    shell:
        # || true prevents the rule from failing when spades throws an error; this happens when unmapped files are too small
        "spades.py --plasmid -1 {input.r1} -2 {input.r2} -t {threads} -o {output} &> {log} || true"

rule assembly_summary:
    input:
        "results/assemblies/{strain}",
        "results/plasmids/{strain}"
    output:
         "results/assemblies_joined/{strain}/summary.tsv"
    threads: 1
    message: "summarizing unicycler and SPAdes assemblies of strain {wildcards.strain}"
    log: "results/logs/{strain}_assembly_summary.log"
    script:
        "scripts/assembly_summary.py"

rule join_assemblies:
    input:
        "results/assemblies/{strain}",
        "results/plasmids/{strain}"
    output:
        "results/assemblies_joined/{strain}/assembly.fasta"
    threads: 1
    message: "joining Unicycler assembly and SPAdes plasmid assembly together, strain {wildcards.strain}"
    log: "results/logs/{strain}_joiner.log"
    script:
        "scripts/join_two_fastas.py"

rule genome_annotation:
    # proteins (prodigal) and rRNA (barrnap)
    input:
        "results/assemblies_joined/{strain}/assembly.fasta"
    output:
        directory("results/annotations/{strain}/prokka")
    threads: 18
    message: "executing PROKKA with {threads} threads on full assembly of {wildcards.strain}"
    log: "results/logs/{strain}_prokka.log"
    conda: "envs/prokka.yaml"
    params: centre="UU", minlen="200", genus="Escherichia", species="coli"
    shell:
        # skip tRNAs search?
        "prokka --addgenes --addmrna --compliant --notrna --outdir {output} --prefix {wildcards.strain}_genomic --centre {params.centre} --genus {params.genus} "
        "--species {params.species} --strain {wildcards.strain} --kingdom Bacteria --cpus {threads} "
        "--mincontiglen {params.minlen} {input} &> {log}"

rule rename_gbk:
    input:
        "results/annotations/{strain}/prokka"
    output:
        "results/annotations/{strain}/prokka_renamed/{strain}_genomic.gbk"
    params:
        filename="{strain}_genomic.gbk"
    script:
        "scripts/rename_genomic_gbk.py"

rule trna_annotation:
    # tRNA genes only - tRNAScan-SE
    input:
        "results/assemblies_joined/{strain}/assembly.fasta"
    output:
        # TODO: use multiext function
        general = "results/annotations/{strain}/trna/trna_gen.txt",
        struct = "results/annotations/{strain}/trna/trna_struct.txt",
        iso = "results/annotations/{strain}/trna/trna_iso.txt",
        stats = "results/annotations/{strain}/trna/trna_stat.txt",
        bed = "results/annotations/{strain}/trna/trna_coords.bed",
        gff = "results/annotations/{strain}/trna/trna_feat.gff",
        fasta = "results/annotations/{strain}/trna/trna_seq.fasta"
    threads: 18
    message: "executing tRNAScan-SE with {threads} threads on full assembly of {wildcards.strain} strain"
    log: "results/logs/{strain}_trnascan.log"
    conda: "envs/trnascan.yaml"
    shell:
        "tRNAscan-SE -B --forceow -o {output.general} -f {output.struct} -s {output.iso} -m {output.stats} -b {output.bed} "
        "-j {output.gff} -a {output.fasta} -l {log} --thread {threads} {input} &> {log}"

rule join_annotations:
    input:
        prokka="results/annotations/{strain}/prokka",
        trnascan="results/annotations/{strain}/trna/trna_seq.fasta"
        # mode="annotation"
    output:
        "results/annotations/{strain}/joined/annotation.fasta"  # it's not supposed to be used as input for RGI tool
    script:
        "scripts/join_two_fastas.py"

rule resistance_genes:
    # it doesn't work with tRNAs
    # ALSO: rgi load --card_json ./card_database/card.json --local
    input:
        "results/annotations/{strain}/prokka"
    output:
        "results/resistance_genes/{strain}/rgi_table.txt" # IT'S JUST A PREFIX!
    threads: 18
    message: "executing RGI with {threads} threads on predicted genes/proteins from {wildcards.strain}"
    log: "results/logs/{strain}_rgi.log"
    conda: "envs/rgi.yaml"
    shell:
        "output=$(echo '{output}' | cut -d'.' -f 1) && "
        "rgi main --input_sequence {input}/{wildcards.strain}_genomic.faa --output_file $output  "
        "--input_type protein --local  --num_threads {threads} --include_loose --clean &> {log}"

rule rg2gbk:
    input:
        "results/resistance_genes/{strain}/rgi_table.txt",
        "results/annotations/{strain}/prokka"
    output:
        "results/annotations/{strain}/resistance_genes/{strain}_resistance_genes.gbk"
    params: filter_criterion="Loose"
    script:
        "scripts/rgi2gff.py"

rule get_coordinates:
    # requires BEDtools, pybedtools and bcbio-gff
    input:
        "results/assemblies_joined/{strain}/assembly.fasta",
        "results/annotations/{strain}/prokka",
        "results/resistance_genes/{strain}/rgi_table.txt"
    output:
       "results/direct_repeats/{strain}/regions/regions_within.bed",
       "results/direct_repeats/{strain}/regions/regions_overlapping_5_end.bed",
       "results/direct_repeats/{strain}/regions/regions_overlapping_3_end.bed"
    message: "creating BED files for RGs flanking regions in {wildcards.strain} assembly"
    log: "results/logs/{strain}_getbed.log"
    params: span=100000, min_plasmid_size=1000
    script:
        "scripts/flanking_regions.py"

rule get_fasta:
    input:
        assembly="results/assemblies_joined/{strain}/assembly.fasta",
        bed_normal="results/direct_repeats/{strain}/regions/regions_within.bed",
        bed_5_end="results/direct_repeats/{strain}/regions/regions_overlapping_5_end.bed",
        bed_3_end="results/direct_repeats/{strain}/regions/regions_overlapping_3_end.bed"
    output:
        normal="results/direct_repeats/{strain}/regions/regions_within.fasta",
        left="results/direct_repeats/{strain}/regions/regions_overlapping_5_end.fasta",
        right="results/direct_repeats/{strain}/regions/regions_overlapping_3_end.fasta"
    message: "retrieving regions' sequences from {wildcards.strain} assembly"
    log: "results/logs/{strain}_bedtools.log"
    conda: "envs/bedtools.yaml"
    shell:
        # bed tools returns an empty file if a bed file is empty
        "bedtools getfasta -fi {input.assembly} -bed {input.bed_normal} -nameOnly -fo {output.normal} &> {log}; "
        "bedtools getfasta -fi {input.assembly} -bed {input.bed_5_end} -nameOnly -fo {output.left} &>> {log}; "
        "bedtools getfasta -fi {input.assembly} -bed {input.bed_3_end} -nameOnly -fo {output.right} &>> {log}"

rule join_ends:
    input:
        "results/direct_repeats/{strain}/regions/regions_within.fasta",
        "results/direct_repeats/{strain}/regions/regions_overlapping_5_end.fasta",
        "results/direct_repeats/{strain}/regions/regions_overlapping_3_end.fasta"
    output:
        "results/direct_repeats/{strain}/regions/regions_within_joined.fasta",
        "results/direct_repeats/{strain}/regions/regions_joined_5_end.fasta",
        "results/direct_repeats/{strain}/regions/regions_joined_3_end.fasta"
    message: "joining regions overlapping chromosome ends in {wildcards.strain} assembly"
    log: "results/logs/{strain}_join_ends.log"
    script:
        "scripts/join_ends.py"

rule concatenate_regions:
    input:
        normal="results/direct_repeats/{strain}/regions/regions_within_joined.fasta",
        left_joined="results/direct_repeats/{strain}/regions/regions_joined_5_end.fasta",
        right_joined="results/direct_repeats/{strain}/regions/regions_joined_3_end.fasta"
    output:
        "results/direct_repeats/{strain}/regions/regions_joined_final.fasta"
    message: "concatenating regions from {wildcards.strain} assembly"
    log: "results/logs/{strain}_concatenate_regions.txt"
    shell:
        "cat {input.normal} {input.left_joined} {input.right_joined} > {output} 2> {log}"

# here I increase min_size of repeat up to 20 because having tested min_size=10 I saw millions these tiny repeats
# which make up 99% of output and make up the longer exact and inexact repeats
# exact counts: 10-20 bp - 623 000, 20-50 bp - 292 and so on
rule direct_repeats:
    input:
        "results/direct_repeats/{strain}/regions/regions_joined_final.fasta"
    output:
        directory("results/direct_repeats/{strain}/repeats_no_mismatch")
    threads: 18
    message: "executing GRF with {threads} threads on {wildcards.strain} assembly"
    log: "results/logs/{strain}_grf_perfect.log"
    conda: "envs/grf.yaml"
    params: mode=2, min_size=20, format=1, mism=0, seed_mism=0, max_spacer=205000, min_spacer=100
    shell:
        "grf-main -i {input} -c {params.mode} -o {output} -t {threads} --min_tr {params.min_size} -f {params.format} "
        "--max_mismatch {params.mism} --seed_mismatch {params.seed_mism} --max_spacer_len {params.max_spacer} --min_spacer_len {params.min_spacer} &> {log} "


rule dr2gff:
    # this rule creates GFF files with local coordinates of the repeats. Local means related to the region around an RG,
    # not the entire genome
    input:
        "results/direct_repeats/{strain}/repeats_no_mismatch",
        "results/annotations/{strain}/prokka"
    output:
        "results/annotations/{strain}/repeats/{strain}_repeats_no_mismatch_perfect.gff",
        "results/annotations/{strain}/repeats/{strain}_repeats_no_mismatch_imperfect.gff"
    message: "executing GFF_parser.py on {wildcards.strain} perfect repeats data"
    params: min_len=20
    log: "results/logs/{strain}_gff_perfect.log"
    script: "scripts/GRF_parser.py"

rule dr2csv:
    # make a csv file with coordinates of each repeat pair (no duplicates)
    input:
        "results/direct_repeats/{strain}/repeats_no_mismatch"
    output:
        "results/annotations/{strain}/repeats/{strain}_repeats.csv"
    message: "making CSV files for repeat pairs in strain {wildcards.strain}"
    log: "results/logs/{strain}_repeats_csv.log"
    script: "scripts/make_repeat_tables.py"

rule dr2centered:
    input:
        "results/direct_repeats/{strain}/regions/regions_within.bed",
        "results/annotations/{strain}/repeats/{strain}_repeats.csv"
    output:
        "results/annotations/{strain}/repeats/{strain}_repeats_centered.csv"
    message: "filtering repeats spanning gene center in strains {wildcards.strain}"
    script: "scripts/filter_repeat_tables.R"

rule final:
    input:
        qc_ass="results/qualcheck_assembly/{strain}",
        qc_ill_raw="results/qualcheck_reads/{strain}/Illumina/{strain}_summary.tsv",
        qc_ill_trim="results/qualcheck_reads/{strain}/Illumina_trimmed/{strain}_summary.tsv",
        qc_nan_raw="results/qualcheck_reads/{strain}/Nanopore/{strain}_summary.tsv",
        qc_nan_filt="results/qualcheck_reads/{strain}/Nanopore_filtered/{strain}_summary.tsv",
        trnascan="results/annotations/{strain}/trna/trna_gen.txt",
        #rgi="results/resistance_genes/{strain}/rgi_table.txt",
        summary="results/assemblies_joined/{strain}/summary.tsv",
        #rep_regions="results/direct_repeats/{strain}/regions/regions.bed",
        #bed="results/direct_repeats/{strain}/regions/regions.fasta",
        #dr_perfect="results/direct_repeats/{strain}/repeats_perfect",
        gff_nomism="results/annotations/{strain}/repeats/{strain}_repeats_no_mismatch_perfect.gff",
        #dr_imperfect="results/direct_repeats/{strain}/repeats_imperfect",
        #gff_mism="results/annotations/{strain}/repeats/{strain}_repeats_mismatch_perfect.gff",
        rg_gbk="results/annotations/{strain}/resistance_genes/{strain}_resistance_genes.gbk",
        renamed_gbk="results/annotations/{strain}/prokka_renamed/{strain}_genomic.gbk",
        dr_csv="results/annotations/{strain}/repeats/{strain}_repeats.csv",
        dr_centered_csv="results/annotations/{strain}/repeats/{strain}_repeats_centered.csv"
    output: touch("results/final/{strain}_all.done")
    shell: "echo 'DONE'"

onsuccess:
    print("Workflow finished, no errors")

