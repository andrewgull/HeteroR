from snakemake.io import touch, directory, temp, expand

configfile: "config.yaml"
# command to run the pipeline on 14 threads and 10Gb of RAM:
# snakemake --use-conda --cores 14 --resources mem_mb=10000
# snakemake --dag results/final/DA63360_all.done | dot -Tpng > dag_new.png

rule all:
    input:
        expand("results/final/{strain}_all.done", strain=config['strains'])

rule QC_illumina_raw:
    input:
        "resources/data_raw/{strain}/Illumina/renamed/{strain}_1.fq.gz"
    output:
        "results/qualcheck_reads/{strain}/Illumina/{strain}_summary.tsv"
    log: "results/logs/{strain}_illumina_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_illumina_trimmed:
    input:
        "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz"
    output:
        "results/qualcheck_reads/{strain}/Illumina_trimmed/{strain}_summary.tsv"
    log: "results/logs/{strain}_trimmed_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_nanopore_raw:  # also builds length distribution plots
    input:
        "resources/data_raw/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        "results/qualcheck_reads/{strain}/Nanopore/{strain}_summary.tsv"
    log: "results/logs/{strain}_nanopore_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule QC_nanopore_filtered:
    input:
        "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        "results/qualcheck_reads/{strain}/Nanopore_filtered/{strain}_summary.tsv"
    log: "results/logs/{strain}_filtered_qc.log"
    conda: "envs/rscripts.yaml"
    script:
        "scripts/run_qualcheck.R"

rule trim_illumina:
    input:
        short_read_1 = "resources/data_raw/{strain}/Illumina/renamed/{strain}_1.fq.gz",
        short_read_2 = "resources/data_raw/{strain}/Illumina/renamed/{strain}_2.fq.gz"
    output:
        short_read_1 = "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz",
        report_html = "results/qualcheck_reads/fastp_reports/{strain}_report.html",
        report_json = "results/qualcheck_reads/fastp_reports/{strain}_report.json"
    wildcard_constraints: strain="DA[0-9]*"
    threads: 14
    message: "executing fastp with {threads} threads on {wildcards.strain} short reads"
    log: "results/logs/{strain}_fastp.log"
    conda: "envs/fastp.yaml"
    params: q="20", W="4", r="20", l="50", f="10"
    shell:
        # -q, --qualified_quality_phred
        # the quality value that a base is qualified. Default 15 means phred quality >=Q15 is qualified. (int [=15])
        # -W, --cut_window_size
        # the window size option shared by cut_front, cut_tail or cut_sliding. Range: 1~1000, default: 4 (int [=4])
        # -r, --cut_right
        # move a sliding window from front to tail, if meet one window with mean quality < threshold,
        # drop the bases in the window and the right part, and then stop.
        # -l, --length_required
        # reads shorter than length_required will be discarded, default is 15. (int [=15])
        # -y, --low_complexity_filter
        # enable low complexity filter. The complexity is defined as the percentage of base that is
        # different from its next base (base[i] != base[i+1]).
        # -f, --trim_front1
        # trimming how many bases in front for read1, default is 0 (int [=0])
        "fastp --in1 {input.short_read_1} --in2 {input.short_read_2} --out1 {output.short_read_1} "
        "--out2 {output.short_read_2} "
        "--thread {threads} --qualified_quality_phred {params.q} --cut_window_size {params.W} "
        "--cut_right {params.r} --length_required {params.l} --trim_front1 {params.f} --low_complexity_filter "
        "--html {output.report_html} --json {output.report_json} &> {log}"

rule filter_nanopore:
    input:
        "resources/data_raw/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    message:
        "executing filtlong on {wildcards.strain} long reads"
    log: "results/logs/{strain}_filtlong.log"
    conda: "envs/filtlong.yaml"
    threads: 14
    shell:
        "filtlong --min_length 5000 --length_weight 1 --keep_percent 20 --target_bases 260000000 {input} 2> {log} | pigz -c -p {threads} > {output}"

rule unicycler:
    input:
        short_read_1 = "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz",
        long_read = "results/data_filtered/{strain}/Nanopore/{strain}_all.fastq.gz"
    output:
        directory("results/assemblies/{strain}")
    threads: 14
    message:
        "executing Unicycler with {threads} threads on {wildcards.strain} reads"
    log:
        "results/logs/{strain}_unicycler.log"
    conda: "envs/unicycler.yaml"
    shell:
        "unicycler -1 {input.short_read_1} -2 {input.short_read_2} -l {input.long_read} -t {threads} -o {output} &> {log}"

rule QC_assembly:
    input:
        "results/assemblies/{strain}",
        "resources/busco_downloads"
    output:
        directory("results/qualcheck_assembly/{strain}")
    threads: 14
    message: "executing BUSCO and QUAST with {threads} threads on {wildcards.strain} assembly"
    conda: "envs/busco_quast.yaml"
    script:
        "scripts/QC_assembly.py"

rule bwa_map:
    input:
        assembly_dir = "results/assemblies/{strain}",
        short_read_1= "results/data_filtered/{strain}/Illumina/{strain}_1.fq.gz",
        short_read_2 = "results/data_filtered/{strain}/Illumina/{strain}_2.fq.gz"
    output:
        # an output file marked as temp is deleted after all rules that use it as an input are completed
        temp("results/mapping/{strain}/assembly.sam")
    threads: 14
    message: "executing BWA with {threads} threads on {wildcards.strain} assembly"
    log: mem = "results/logs/{strain}_bwa_mem.log",
         index = "results/logs/{strain}_bwa_index.log"
    conda: "envs/bwa.yaml"
    shell:
        "bwa index {input.assembly_dir}/assembly.fasta &> {log.index} && "
        "bwa mem -t {threads} {input.assembly_dir}/assembly.fasta {input.short_read_1} {input.short_read_2} -o {output} &> {log.mem}"

rule samtools:
    input:
        "results/mapping/{strain}/assembly.sam"
    output:
        "results/mapping/{strain}/assembly.bam"
    threads: 14
    message: "executing SAMTOOLS: VIEW-SORT with {threads} threads on {wildcards.strain} mapping file"
    log: "results/logs/{strain}_samtools.log"
    conda: "envs/samtools.yaml"
    shell:
        "samtools view -b {input} | samtools sort -o {output} -O BAM -@ {threads} &> {log} && samtools index {output}"

rule unmapped:
    input:
        "results/mapping/{strain}/assembly.bam"
    output:
        r1 = "results/mapping/{strain}/unmapped_1.fastq",
        r2 = "results/mapping/{strain}/unmapped_2.fastq"
    threads: 14
    message: "executing SAMTOOLS: VIEW-FASTQ with {threads} threads on {wildcards.strain} BAM file"
    log: "results/logs/{strain}_unmapped.log"
    conda: "envs/samtools.yaml"
    shell:
        "samtools view -@ {threads} -u -f 12 -F 256 {input} | samtools fastq -1 {output.r1} -2 {output.r2} -@ {threads} &> {log}"

rule plasmid_assembly:
    input:
        r1 = "results/mapping/{strain}/unmapped_1.fastq",
        r2 = "results/mapping/{strain}/unmapped_2.fastq"
    output:
        directory("results/plasmids/{strain}")
    threads: 14
    message: "executing SPAdes in plasmid mode with {threads} threads on unmapped reads of {wildcards.strain}"
    log: "results/logs/{strain}_spades.log"
    conda: "envs/spades.yaml"
    shell:
        # || true prevents the rule from failing when spades throws an error; this happens when unmapped files are too small
        "spades.py --plasmid -1 {input.r1} -2 {input.r2} -t {threads} -o {output} &> {log} || true"

rule assembly_summary:
    input:
        "results/assemblies/{strain}",
        "results/plasmids/{strain}"
    output:
         "results/assemblies_joined/{strain}/summary.tsv"
    threads: 1
    message: "summarizing unicycler and SPAdes assemblies of strain {wildcards.strain}"
    log: "results/logs/{strain}_assembly_summary.log"
    script:
        "scripts/assembly_summary.py"

rule join_assemblies:
    input:
        "results/assemblies/{strain}",
        "results/plasmids/{strain}"
    output:
        "results/assemblies_joined/{strain}/assembly.fasta"
    threads: 1
    message: "joining Unicycler assembly and SPAdes plasmid assembly together, strain {wildcards.strain}"
    log: "results/logs/{strain}_joiner.log"
    script:
        "scripts/join_two_fastas.py"

rule genome_annotation:
    # proteins (prodigal) and rRNA (barrnap)
    input:
        "results/assemblies_joined/{strain}/assembly.fasta"
    output:
        directory("results/annotations/{strain}/prokka")
    threads: 14
    message: "executing PROKKA with {threads} threads on full assembly of {wildcards.strain}"
    log: "results/logs/{strain}_prokka.log"
    conda: "envs/prokka.yaml"
    params: centre="UU", minlen="200", genus="Escherichia", species="coli"
    shell:
        # skip tRNAs search?
        "prokka --addgenes --addmrna --compliant --notrna --outdir {output} --prefix {wildcards.strain}_genomic --centre {params.centre} --genus {params.genus} "
        "--species {params.species} --strain {wildcards.strain} --kingdom Bacteria --cpus {threads} "
        "--mincontiglen {params.minlen} {input} &> {log}"

rule rename_gbk:
    input:
        "results/annotations/{strain}/prokka"
    output:
        "results/annotations/{strain}/prokka_renamed/{strain}_genomic.gbk"
    params:
        filename="{strain}_genomic.gbk"
    script:
        "scripts/rename_genomic_gbk.py"

rule trna_annotation:
    # tRNA genes only - tRNAScan-SE
    input:
        "results/assemblies_joined/{strain}/assembly.fasta"
    output:
        # TODO: use multiext function
        general = "results/annotations/{strain}/trna/trna_gen.txt",
        struct = "results/annotations/{strain}/trna/trna_struct.txt",
        iso = "results/annotations/{strain}/trna/trna_iso.txt",
        stats = "results/annotations/{strain}/trna/trna_stat.txt",
        bed = "results/annotations/{strain}/trna/trna_coords.bed",
        gff = "results/annotations/{strain}/trna/trna_feat.gff",
        fasta = "results/annotations/{strain}/trna/trna_seq.fasta"
    threads: 14
    message: "executing tRNAScan-SE with {threads} threads on full assembly of {wildcards.strain} strain"
    log: "results/logs/{strain}_trnascan.log"
    conda: "envs/trnascan.yaml"
    shell:
        "tRNAscan-SE -B --forceow -o {output.general} -f {output.struct} -s {output.iso} -m {output.stats} -b {output.bed} "
        "-j {output.gff} -a {output.fasta} -l {log} --thread {threads} {input} &> {log}"

rule join_annotations:
    input:
        prokka="results/annotations/{strain}/prokka",
        trnascan="results/annotations/{strain}/trna/trna_seq.fasta"
        # mode="annotation"
    output:
        "results/annotations/{strain}/joined/annotation.fasta"  # it's not supposed to be used as input for RGI tool
    script:
        "scripts/join_two_fastas.py"

rule resistance_genes:
    # it doesn't work with tRNAs
    # ALSO: rgi load --card_json ./card_database/card.json --local
    input:
        "results/annotations/{strain}/prokka"
    output:
        "results/resistance_genes/{strain}/rgi_table.txt" # IT'S JUST A PREFIX!
    threads: 14
    message: "executing RGI with {threads} threads on predicted genes/proteins from {wildcards.strain}"
    log: "results/logs/{strain}_rgi.log"
    conda: "envs/rgi.yaml"
    shell:
        "output=$(echo '{output}' | cut -d'.' -f 1) && "
        "rgi main --input_sequence {input}/{wildcards.strain}_genomic.faa --output_file $output  "
        "--input_type protein --local  --num_threads {threads} --include_loose --clean &> {log}"

rule rg2gbk:
    input:
        "results/resistance_genes/{strain}/rgi_table.txt",
        "results/annotations/{strain}/prokka/{strain}_genomic.gbk"
    output:
        "results/annotations/{strain}/resistance_genes/{strain}_resistance_genes.gbk"
    params: filter_criterion="Loose"
    script:
        "scripts/rgi2gff.py"

rule get_coordinates:
    # requires BEDtools, pybedtools and bcbio-gff
    input:
        "results/assemblies_joined/{strain}/assembly.fasta",
        "results/annotations/{strain}/prokka/{strain}_genomic.gff",
        "results/resistance_genes/{strain}/rgi_table.txt"
    output:
       "results/direct_repeats/{strain}/regions/regions.bed"
    message: "creating BED files for RGs found in {wildcards.strain} assembly"
    log: "results/logs/{strain}_getbed.log"
    params: span=100000, min_plasmid_size=1000
    script:
        "scripts/flanking_regions.py"

rule get_fasta:
    input:
        assembly="results/assemblies_joined/{strain}/assembly.fasta",
        bed="results/direct_repeats/{strain}/regions/regions.bed"
    output:
        "results/direct_repeats/{strain}/regions/regions.fasta"
    message: "retrieving regions' sequences from {wildcards.strain} assembly"
    log: "results/logs/{strain}_bedtools.log"
    conda: "envs/bedtools.yaml"
    shell:
        "bedtools getfasta -fi {input.assembly} -bed {input.bed} -fo {output} &> {log}"

rule direct_repeats_perfect:
    input:
        "results/direct_repeats/{strain}/regions/regions.fasta"
    output:
        directory("results/direct_repeats/{strain}/repeats_perfect")
    threads: 14
    message: "executing GRF with {threads} threads on {wildcards.strain} assembly"
    log: "results/logs/{strain}_grf_perfect.log"
    conda: "envs/grf.yaml"
    params: mode=2, min_size=10, format=1, mism=0, seed_mism=0, max_dist=205000, min_dist=100
    shell:
        "grf-main -i {input} -c {params.mode} -o {output} -t {threads} --min_tr {params.min_size} -f {params.format} "
        "--max_mismatch {params.mism} --seed_mismatch {params.seed_mism} --max_space {params.max_dist} --min_space {params.min_dist} &> {log} "

rule drp2gff:
    input:
        "results/direct_repeats/{strain}/repeats_perfect",
        "results/assemblies_joined/{strain}/assembly.fasta"
    output: "results/annotations/{strain}/repeats/{strain}_repeats_perfect.gff"
    message: "executing GFF_parser.py on {wildcards.strain} perfect repeats data"
    params: min_len=15, mode="perfect" # TODO: make use of the new parameter
    log: "results/logs/{strain}_gff_perfect.log"
    script: "scripts/GRF_parser.py"

rule direct_repeats_imperfect:
    input:
        "results/direct_repeats/{strain}/regions/regions.fasta"
    output:
        directory("results/direct_repeats/{strain}/repeats_imperfect")
    threads: 14
    message: "executing GRF (with mismatches) with {threads} threads on {wildcards.strain} assembly"
    log: "results/logs/{strain}_grf_imperfect.log"
    conda: "envs/grf.yaml"
    params: mode=2, min_size=10, format=1, mism=10, seed_mism=0, max_dist=205000, min_dist=100
    shell:
        "grf-main -i {input} -c {params.mode} -o {output} -t {threads} --min_tr {params.min_size} -f {params.format} "
        "--max_mismatch {params.mism} --seed_mismatch {params.seed_mism} --max_space {params.max_dist} --min_space {params.min_dist} &> {log} "

rule dri2gff:
    # make GFF with imperfect repeats coords
    input:
        "results/direct_repeats/{strain}/repeats_perfect",
        "results/assemblies_joined/{strain}/assembly.fasta"
    output: "results/annotations/{strain}/repeats/{strain}_repeats_imperfect.gff"
    message: "executing GFF_parser.py on {wildcards.strain} imperfect repeats data"
    params: min_len=15, mode="imperfect"
    log: "results/logs/{strain}_gff_imperfect.log"
    script: "scripts/GRF_parser.py"  # TODO: new parsing script is required

rule final:
    input:
        qc_ass="results/qualcheck_assembly/{strain}",
        qc_ill_raw="results/qualcheck_reads/{strain}/Illumina/{strain}_summary.tsv",
        qc_ill_trim="results/qualcheck_reads/{strain}/Illumina_trimmed/{strain}_summary.tsv",
        qc_nan_raw="results/qualcheck_reads/{strain}/Nanopore/{strain}_summary.tsv",
        qc_nan_filt="results/qualcheck_reads/{strain}/Nanopore_filtered/{strain}_summary.tsv",
        trnascan="results/annotations/{strain}/trna/trna_gen.txt",
        rgi="results/resistance_genes/{strain}/rgi_table.txt",
        summary="results/assemblies_joined/{strain}/summary.tsv",
        rep_regions="results/direct_repeats/{strain}/regions/regions.bed",
        bed="results/direct_repeats/{strain}/regions/regions.fasta",
        dr_perfect="results/direct_repeats/{strain}/repeats_perfect",
        gff_perfect="results/annotations/{strain}/repeats/{strain}_repeats_perfect.gff",
        dr_imperfect="results/direct_repeats/{strain}/repeats_imperfect",
        gff_imperfect="results/annotations/{strain}/repeats/{strain}_repeats_imperfect.gff",
        rg_gbk="results/annotations/{strain}/resistance_genes/{strain}_resistance_genes.gbk",
        renamed_gbk="results/annotations/{strain}/prokka_renamed/{strain}_genomic.gbk"
    output: touch("results/final/{strain}_all.done")
    shell: "echo 'DONE'"

onsuccess:
    print("Workflow finished, no errors")

